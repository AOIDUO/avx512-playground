push   %rbp
push   %r15
push   %r14
push   %r13
push   %r12
push   %rbx
test   %edi,%edi
jle    bc9e <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0x7ae>
test   %esi,%esi
jle    bc9e <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0x7ae>
mov    (%rcx),%r10
mov    %esi,%eax
lea    0x0(,%rax,4),%rcx
mov    (%r8),%r15
mov    (%rdx),%r9
mov    %eax,%r8d
and    $0x7,%r8d
mov    %edi,%r12d
xor    %r13d,%r13d
mov    %esi,-0x54(%rsp)
mov    %r12,-0x28(%rsp)
mov    %r8,-0x60(%rsp)
mov    %rcx,-0x8(%rsp)
mov    %eax,%ecx
and    $0xffffffe0,%ecx
mov    %rcx,-0x30(%rsp)
add    $0xffffffffffffffe0,%rcx
mov    %rcx,-0x38(%rsp)
shr    $0x5,%rcx
inc    %rcx
mov    %r9,-0x10(%rsp)
mov    %r10,-0x18(%rsp)
mov    %r15,-0x20(%rsp)
mov    %ecx,%edx
and    $0x7,%edx
and    $0xfffffffffffffff8,%rcx
mov    %rdx,-0x40(%rsp)
shl    $0x7,%rdx
mov    %rcx,-0x50(%rsp)
mov    %rdx,-0x48(%rsp)
jmp    b59c <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0xac>
data16 data16 cs nopw 0x0(%rax,%rax,1)
inc    %r13
cmp    %r12,%r13
je     bc9e <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0x7ae>
lea    0x0(,%r13,8),%rcx
lea    (%rcx,%rcx,2),%rcx
mov    (%r9,%rcx,1),%rbp
mov    (%r10,%rcx,1),%r11
mov    (%r15,%rcx,1),%r14
cmp    $0x20,%esi
jae    b680 <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0x190>
xor    %ecx,%ecx
mov    %rcx,%rbx
not    %rbx
add    %rax,%rbx
test   %r8,%r8
je     b5e5 <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0xf5>
mov    %r8,%rdx
mov    (%r11,%rcx,4),%edi
imul   0x0(%rbp,%rcx,4),%edi
add    %edi,(%r14,%rcx,4)
inc    %rcx
dec    %rdx
jne    b5d0 <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0xe0>
cmp    $0x7,%rbx
jb     b590 <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0xa0>
nopl   0x0(%rax,%rax,1)
mov    (%r11,%rcx,4),%edx
imul   0x0(%rbp,%rcx,4),%edx
add    %edx,(%r14,%rcx,4)
mov    0x4(%r11,%rcx,4),%edx
imul   0x4(%rbp,%rcx,4),%edx
add    %edx,0x4(%r14,%rcx,4)
mov    0x8(%r11,%rcx,4),%edx
imul   0x8(%rbp,%rcx,4),%edx
add    %edx,0x8(%r14,%rcx,4)
mov    0xc(%r11,%rcx,4),%edx
imul   0xc(%rbp,%rcx,4),%edx
add    %edx,0xc(%r14,%rcx,4)
mov    0x10(%r11,%rcx,4),%edx
imul   0x10(%rbp,%rcx,4),%edx
add    %edx,0x10(%r14,%rcx,4)
mov    0x14(%r11,%rcx,4),%edx
imul   0x14(%rbp,%rcx,4),%edx
add    %edx,0x14(%r14,%rcx,4)
mov    0x18(%r11,%rcx,4),%edx
imul   0x18(%rbp,%rcx,4),%edx
add    %edx,0x18(%r14,%rcx,4)
mov    0x1c(%r11,%rcx,4),%edx
imul   0x1c(%rbp,%rcx,4),%edx
add    %edx,0x1c(%r14,%rcx,4)
add    $0x8,%rcx
cmp    %rcx,%rax
jne    b5f0 <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0x100>
jmp    b590 <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0xa0>
data16 data16 cs nopw 0x0(%rax,%rax,1)
mov    -0x8(%rsp),%rdi
lea    0x0(%rbp,%rdi,1),%rcx
lea    (%r14,%rdi,1),%rdx
add    %r11,%rdi
cmp    %rcx,%r14
setb   %r8b
cmp    %rdx,%rbp
setb   %bl
cmp    %rdi,%r14
setb   %cl
cmp    %rdx,%r11
setb   %dl
test   %bl,%r8b
jne    b6d4 <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0x1e4>
mov    -0x60(%rsp),%r8
and    %dl,%cl
mov    $0x0,%ecx
jne    b5bf <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0xcf>
cmpq   $0xe0,-0x38(%rsp)
jae    b6de <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0x1ee>
xor    %r15d,%r15d
jmp    bbd1 <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0x6e1>
mov    -0x60(%rsp),%r8
jmp    b5bd <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0xcd>
mov    -0x50(%rsp),%r12
lea    0x3e0(%rbp),%r8
lea    0x3e0(%r11),%r9
lea    0x3e0(%r14),%r10
xor    %r15d,%r15d
nopl   0x0(%rax,%rax,1)
vmovdqu -0x3e0(%r9,%r15,4),%ymm0
vmovdqu -0x3c0(%r9,%r15,4),%ymm1
vmovdqu -0x3a0(%r9,%r15,4),%ymm2
vmovdqu -0x380(%r9,%r15,4),%ymm3
vpmulld -0x3e0(%r8,%r15,4),%ymm0,%ymm0
vpmulld -0x3c0(%r8,%r15,4),%ymm1,%ymm1
vpmulld -0x3a0(%r8,%r15,4),%ymm2,%ymm2
vpmulld -0x380(%r8,%r15,4),%ymm3,%ymm3
vpaddd -0x3e0(%r10,%r15,4),%ymm0,%ymm0
vpaddd -0x3c0(%r10,%r15,4),%ymm1,%ymm1
vpaddd -0x3a0(%r10,%r15,4),%ymm2,%ymm2
vpaddd -0x380(%r10,%r15,4),%ymm3,%ymm3
vmovdqu %ymm0,-0x3e0(%r10,%r15,4)
vmovdqu %ymm1,-0x3c0(%r10,%r15,4)
vmovdqu %ymm2,-0x3a0(%r10,%r15,4)
vmovdqu %ymm3,-0x380(%r10,%r15,4)
vmovdqu -0x360(%r9,%r15,4),%ymm0
vmovdqu -0x340(%r9,%r15,4),%ymm1
vmovdqu -0x320(%r9,%r15,4),%ymm2
vmovdqu -0x300(%r9,%r15,4),%ymm3
vpmulld -0x360(%r8,%r15,4),%ymm0,%ymm0
vpmulld -0x340(%r8,%r15,4),%ymm1,%ymm1
vpmulld -0x320(%r8,%r15,4),%ymm2,%ymm2
vpmulld -0x300(%r8,%r15,4),%ymm3,%ymm3
vpaddd -0x360(%r10,%r15,4),%ymm0,%ymm0
vpaddd -0x340(%r10,%r15,4),%ymm1,%ymm1
vpaddd -0x320(%r10,%r15,4),%ymm2,%ymm2
vpaddd -0x300(%r10,%r15,4),%ymm3,%ymm3
vmovdqu %ymm0,-0x360(%r10,%r15,4)
vmovdqu %ymm1,-0x340(%r10,%r15,4)
vmovdqu %ymm2,-0x320(%r10,%r15,4)
vmovdqu %ymm3,-0x300(%r10,%r15,4)
vmovdqu -0x2e0(%r9,%r15,4),%ymm0
vmovdqu -0x2c0(%r9,%r15,4),%ymm1
vmovdqu -0x2a0(%r9,%r15,4),%ymm2
vmovdqu -0x280(%r9,%r15,4),%ymm3
vpmulld -0x2e0(%r8,%r15,4),%ymm0,%ymm0
vpmulld -0x2c0(%r8,%r15,4),%ymm1,%ymm1
vpmulld -0x2a0(%r8,%r15,4),%ymm2,%ymm2
vpmulld -0x280(%r8,%r15,4),%ymm3,%ymm3
vpaddd -0x2e0(%r10,%r15,4),%ymm0,%ymm0
vpaddd -0x2c0(%r10,%r15,4),%ymm1,%ymm1
vpaddd -0x2a0(%r10,%r15,4),%ymm2,%ymm2
vpaddd -0x280(%r10,%r15,4),%ymm3,%ymm3
vmovdqu %ymm0,-0x2e0(%r10,%r15,4)
vmovdqu %ymm1,-0x2c0(%r10,%r15,4)
vmovdqu %ymm2,-0x2a0(%r10,%r15,4)
vmovdqu %ymm3,-0x280(%r10,%r15,4)
vmovdqu -0x260(%r9,%r15,4),%ymm0
vmovdqu -0x240(%r9,%r15,4),%ymm1
vmovdqu -0x220(%r9,%r15,4),%ymm2
vmovdqu -0x200(%r9,%r15,4),%ymm3
vpmulld -0x260(%r8,%r15,4),%ymm0,%ymm0
vpmulld -0x240(%r8,%r15,4),%ymm1,%ymm1
vpmulld -0x220(%r8,%r15,4),%ymm2,%ymm2
vpmulld -0x200(%r8,%r15,4),%ymm3,%ymm3
vpaddd -0x260(%r10,%r15,4),%ymm0,%ymm0
vpaddd -0x240(%r10,%r15,4),%ymm1,%ymm1
vpaddd -0x220(%r10,%r15,4),%ymm2,%ymm2
vpaddd -0x200(%r10,%r15,4),%ymm3,%ymm3
vmovdqu %ymm0,-0x260(%r10,%r15,4)
vmovdqu %ymm1,-0x240(%r10,%r15,4)
vmovdqu %ymm2,-0x220(%r10,%r15,4)
vmovdqu %ymm3,-0x200(%r10,%r15,4)
vmovdqu -0x1e0(%r9,%r15,4),%ymm0
vmovdqu -0x1c0(%r9,%r15,4),%ymm1
vmovdqu -0x1a0(%r9,%r15,4),%ymm2
vmovdqu -0x180(%r9,%r15,4),%ymm3
vpmulld -0x1e0(%r8,%r15,4),%ymm0,%ymm0
vpmulld -0x1c0(%r8,%r15,4),%ymm1,%ymm1
vpmulld -0x1a0(%r8,%r15,4),%ymm2,%ymm2
vpmulld -0x180(%r8,%r15,4),%ymm3,%ymm3
vpaddd -0x1e0(%r10,%r15,4),%ymm0,%ymm0
vpaddd -0x1c0(%r10,%r15,4),%ymm1,%ymm1
vpaddd -0x1a0(%r10,%r15,4),%ymm2,%ymm2
vpaddd -0x180(%r10,%r15,4),%ymm3,%ymm3
vmovdqu %ymm0,-0x1e0(%r10,%r15,4)
vmovdqu %ymm1,-0x1c0(%r10,%r15,4)
vmovdqu %ymm2,-0x1a0(%r10,%r15,4)
vmovdqu %ymm3,-0x180(%r10,%r15,4)
vmovdqu -0x160(%r9,%r15,4),%ymm0
vmovdqu -0x140(%r9,%r15,4),%ymm1
vmovdqu -0x120(%r9,%r15,4),%ymm2
vmovdqu -0x100(%r9,%r15,4),%ymm3
vpmulld -0x160(%r8,%r15,4),%ymm0,%ymm0
vpmulld -0x140(%r8,%r15,4),%ymm1,%ymm1
vpmulld -0x120(%r8,%r15,4),%ymm2,%ymm2
vpmulld -0x100(%r8,%r15,4),%ymm3,%ymm3
vpaddd -0x160(%r10,%r15,4),%ymm0,%ymm0
vpaddd -0x140(%r10,%r15,4),%ymm1,%ymm1
vpaddd -0x120(%r10,%r15,4),%ymm2,%ymm2
vpaddd -0x100(%r10,%r15,4),%ymm3,%ymm3
vmovdqu %ymm0,-0x160(%r10,%r15,4)
vmovdqu %ymm1,-0x140(%r10,%r15,4)
vmovdqu %ymm2,-0x120(%r10,%r15,4)
vmovdqu %ymm3,-0x100(%r10,%r15,4)
vmovdqu -0xe0(%r9,%r15,4),%ymm0
vmovdqu -0xc0(%r9,%r15,4),%ymm1
vmovdqu -0xa0(%r9,%r15,4),%ymm2
vmovdqu -0x80(%r9,%r15,4),%ymm3
vpmulld -0xe0(%r8,%r15,4),%ymm0,%ymm0
vpmulld -0xc0(%r8,%r15,4),%ymm1,%ymm1
vpmulld -0xa0(%r8,%r15,4),%ymm2,%ymm2
vpmulld -0x80(%r8,%r15,4),%ymm3,%ymm3
vpaddd -0xe0(%r10,%r15,4),%ymm0,%ymm0
vpaddd -0xc0(%r10,%r15,4),%ymm1,%ymm1
vpaddd -0xa0(%r10,%r15,4),%ymm2,%ymm2
vpaddd -0x80(%r10,%r15,4),%ymm3,%ymm3
vmovdqu %ymm0,-0xe0(%r10,%r15,4)
vmovdqu %ymm1,-0xc0(%r10,%r15,4)
vmovdqu %ymm2,-0xa0(%r10,%r15,4)
vmovdqu %ymm3,-0x80(%r10,%r15,4)
vmovdqu -0x60(%r9,%r15,4),%ymm0
vmovdqu -0x40(%r9,%r15,4),%ymm1
vmovdqu -0x20(%r9,%r15,4),%ymm2
vmovdqu (%r9,%r15,4),%ymm3
vpmulld -0x60(%r8,%r15,4),%ymm0,%ymm0
vpmulld -0x40(%r8,%r15,4),%ymm1,%ymm1
vpmulld -0x20(%r8,%r15,4),%ymm2,%ymm2
vpmulld (%r8,%r15,4),%ymm3,%ymm3
vpaddd -0x60(%r10,%r15,4),%ymm0,%ymm0
vpaddd -0x40(%r10,%r15,4),%ymm1,%ymm1
vpaddd -0x20(%r10,%r15,4),%ymm2,%ymm2
vpaddd (%r10,%r15,4),%ymm3,%ymm3
vmovdqu %ymm0,-0x60(%r10,%r15,4)
vmovdqu %ymm1,-0x40(%r10,%r15,4)
vmovdqu %ymm2,-0x20(%r10,%r15,4)
vmovdqu %ymm3,(%r10,%r15,4)
add    $0x100,%r15
add    $0xfffffffffffffff8,%r12
jne    b700 <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0x210>
cmpq   $0x0,-0x40(%rsp)
mov    -0x10(%rsp),%r12
mov    -0x18(%rsp),%r10
mov    -0x28(%rsp),%rsi
mov    -0x60(%rsp),%r8
mov    -0x48(%rsp),%r9
je     bc79 <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0x789>
lea    0x60(%r14,%r15,4),%rcx
lea    0x60(%r11,%r15,4),%rbx
lea    0x60(%rbp,%r15,4),%rdi
xor    %edx,%edx
nopw   0x0(%rax,%rax,1)
vmovdqu -0x60(%rbx,%rdx,1),%ymm0
vmovdqu -0x40(%rbx,%rdx,1),%ymm1
vmovdqu -0x20(%rbx,%rdx,1),%ymm2
vmovdqu (%rbx,%rdx,1),%ymm3
vpmulld -0x60(%rdi,%rdx,1),%ymm0,%ymm0
vpmulld -0x40(%rdi,%rdx,1),%ymm1,%ymm1
vpmulld -0x20(%rdi,%rdx,1),%ymm2,%ymm2
vpmulld (%rdi,%rdx,1),%ymm3,%ymm3
vpaddd -0x60(%rcx,%rdx,1),%ymm0,%ymm0
vpaddd -0x40(%rcx,%rdx,1),%ymm1,%ymm1
vpaddd -0x20(%rcx,%rdx,1),%ymm2,%ymm2
vpaddd (%rcx,%rdx,1),%ymm3,%ymm3
vmovdqu %ymm0,-0x60(%rcx,%rdx,1)
vmovdqu %ymm1,-0x40(%rcx,%rdx,1)
vmovdqu %ymm2,-0x20(%rcx,%rdx,1)
vmovdqu %ymm3,(%rcx,%rdx,1)
sub    $0xffffffffffffff80,%rdx
cmp    %rdx,%r9
jne    bc10 <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0x720>
mov    -0x30(%rsp),%rdx
mov    %r12,%r9
mov    %rsi,%r12
mov    -0x20(%rsp),%r15
mov    -0x54(%rsp),%esi
mov    %rdx,%rcx
cmp    %rax,%rdx
je     b590 <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0xa0>
jmp    b5bf <_Z2xxiiRSt6vectorIS_IjSaIjEESaIS1_EES4_S4_+0xcf>
pop    %rbx
pop    %r12
pop    %r13
pop    %r14
pop    %r15
pop    %rbp
vzeroupper
ret
nopl   0x0(%rax
